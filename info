Field,Response
Use Case Name,GenAI-Driven Test Case Generation and Impact Assessment
Additional Project Contacts,"QA Automation Lead, Business Analyst for Regulatory Projects, Data Engineering SME (for lineage and system architecture)"
Description,"This use case applies Generative AI to automate the generation of test cases from JIRA requirements, policy documents, and testing guidelines. The system uses Retrieval-Augmented Generation (RAG) to parse domain-specific information, map it to business logic, and produce exploratory, regression, and downstream-impact test scenarios. It highlights missing information in requirements and recommends refinements by validating inputs, outputs, and lineage dependencies."
Target Audience,"Testing Center of Excellence (TCoE), QA/Test Analysts and Leads, Agile Delivery Teams, Compliance and Risk Stakeholders, Data and Reporting Teams"
Business Purpose,"To improve efficiency, effectiveness, and governance in QA by:
- Reducing manual test design effort
- Detecting requirement gaps early
- Standardizing testing practices
- Enhancing traceability and downstream coverage"
Capability,"- Auto-generation of test cases (exploratory, regression, impact-based)
- JIRA integration and requirement parsing
- RAG-based contextual response
- Financial/reporting impact analysis
- Prompt-based suggestion of test scenarios
- Upstream/downstream dependency checks"
AI Methodology,"- RAG (Retrieval-Augmented Generation) to feed LLM with domain knowledge at query time
- Pre-trained LLMs (e.g., OpenAI GPT-3.5, Mistral, TinyLLaMA) enhanced via fine-tuning and prompt engineering
- Vector database to index policy docs, JIRA, lineage, and previous test cases
- AI-generated markdown-style test cases mapped to test strategy"
Project Benefits,"- Accelerated and consistent test case design
- Reduced redundancy and early detection of requirement gaps
- Improved test coverage across downstream systems
- Lower rework due to better alignment with real impacts
- Standardized QA governance across projects"
Provide Additional Details,"The system processes inputs from policy documents, JIRA tickets, and data lineage flows (ETL/SQL). It builds a vector database and leverages a user interface to allow prompt-based test generation. The solution integrates with Streamlit dashboards and BigQuery-based RAFT automation framework, producing output in a reusable format (e.g., markdown tables) tagged with traceability and impact logic."
Estimated Development/Rollout Cost (USD),"$30,000 (approx. for pilot rollout, model tuning, UI, and integration)"
Has the AI use case been identified as an AI Flagship?,No
Select your AI Review Forum,[Select based on internal governance � likely: Data & AI Innovation Council or Technology Design Authority]
Is this use case dependent on any other infrastructure/platform applications for the delivery of its outputs?,"Yes � JIRA, Streamlit, BigQuery, Excel, internal data catalog"
Is this use case dependent on any data platform applications for the delivery of its outputs?,"Yes � BigQuery, ETL pipelines, SQL lineage files"
Primary Application,QA Automation and Testing Intelligence

