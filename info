Below is a single, copy-paste prompt for GitHub Copilot.
It tells Copilot to generate two files — tools/deps_scan.py and build_exe.sh — with no optional branches and no requirements.txt usage. The script will always: create a venv, auto-detect imports from launcher.py and app.py, install them, pin Streamlit/Altair to safe versions, and build a single-file EXE using PyInstaller with the right collectors.

⸻

Prompt for Copilot (paste as a comment in your repo)

You are GitHub Copilot. Create two files with the exact content described below. Do not ask questions.

Overview

Generate a Git Bash build pipeline for Windows that works without requirements.txt and without optional switches.
	•	Files present beside the script: launcher.py (entry) and app.py (Streamlit app).
	•	Output: dist/launcher.exe and requirements-lock.txt.
	•	The script must be deterministic and handle dynamic imports commonly used by Streamlit and data libs.

⸻

1) Create file: tools/deps_scan.py

Purpose: statically extract third-party dependencies from launcher.py and app.py and print pip package names (one per line) to STDOUT.

Requirements:
	•	Use ast to parse imports (no regex).
	•	Collect import X and from X import Y.
	•	Exclude stdlib modules and local/relative imports.
	•	Map common module names to pip package names using an internal dictionary:
	•	streamlit→streamlit, altair→altair, pandas→pandas, numpy→numpy, pyyaml→pyyaml, toml→toml, pydantic→pydantic, requests→requests, opencv-python for cv2, scikit-learn for sklearn, pandas-gbq for pandas_gbq, google-cloud-bigquery for google.cloud.bigquery, google-cloud-storage for google.cloud.storage, grpcio for grpc, google-crc32c for google_crc32c, protobuf→protobuf, pyarrow→pyarrow, matplotlib→matplotlib, plotly→plotly.
	•	If a module path contains dots (e.g., google.cloud.bigquery), map from the leftmost matching key in the map where applicable.
	•	Output a unique, sorted list; tolerate missing files (if app.py or launcher.py absent, skip silently).

Program outline Copilot must implement:
	1.	read_code(path) helper.
	2.	extract_modules(code) using ast.
	3.	is_stdlib(mod) using importlib.util.find_spec and sys.base_prefix heuristic; maintain a small allowlist of known third-party names (e.g., streamlit, altair, pandas, etc.) to avoid false stdlib positives.
	4.	map_to_pip(mod) using the mapping table and fallback to the top-level package name.
	5.	Print packages one per line.

⸻

2) Create file: build_exe.sh

Shebang and safety:

#!/usr/bin/env bash
set -euo pipefail

Behavior (no options, no prompts):
	1.	Discover Python in this order: py -3, py, python3, python. Exit with clear error if none found. Echo the chosen interpreter path.
	2.	Check files: ensure launcher.py and app.py exist in the current directory; else exit with error.
	3.	Create and activate venv at .venv (Windows Git Bash activation path: source .venv/Scripts/activate). Then:
	•	python -m pip install --upgrade pip wheel
	4.	Auto-detect and install deps:
	•	Run python tools/deps_scan.py > requirements-auto.txt
	•	Install everything from requirements-auto.txt (if empty, still succeed).
	•	Always install the pinned, known-good build set to avoid Streamlit/Altair packaging failures:
	•	streamlit==1.28.2
	•	altair==4.2.2
	•	pyinstaller==6.6.0
	•	certifi
	•	If any of the detected packages include one of these prefixes, also install the runtime libs they need (no user option flags):
	•	If any package name starts with google-cloud- or pandas-gbq: install grpcio, protobuf, pyarrow, google-crc32c, pandas-gbq (if not already).
	•	Write pip freeze > requirements-lock.txt.
	5.	Clean previous artifacts: remove build/, dist/, and launcher.spec if they exist.
	6.	PyInstaller build (single file):
	•	Base flags (always):

--clean
--onefile
--name launcher
--collect-all streamlit
--collect-all altair
--collect-data certifi
--hidden-import=altair.vegalite.v4


	•	Dynamic collectors based on detected packages (parse requirements-auto.txt):
	•	If any package line contains google-cloud- → add --collect-all google.api --collect-all google.cloud
	•	If any contains grpcio → add --collect-all grpc
	•	If any contains google-crc32c → add --collect-all google_crc32c
	•	If any contains pandas → add --collect-all pandas
	•	If any contains pyarrow → add --collect-all pyarrow
	•	Hidden imports when GCP stack detected:
--hidden-import=google.cloud.bigquery --hidden-import=google.cloud.bigquery_storage_v1 --hidden-import=pandas_gbq
	•	Run pyinstaller with the assembled flags on launcher.py.

	7.	Post-build checks:
	•	Verify dist/launcher.exe exists.
	•	Echo the absolute path to the EXE and to requirements-lock.txt.
	•	Exit non-zero with an error message if the EXE is missing.
	8.	Helpful runtime log hint (comment only):
	•	Add a comment block showing a minimal robust launcher.py snippet that sets:
	•	STREAMLIT_SERVER_HEADLESS=true
	•	STREAMLIT_GLOBAL_DEVELOPMENT_MODE=false
	•	runs from streamlit.web import bootstrap with server.port=8555.

Make the script self-contained: it must run as:

bash build_exe.sh

from the folder where launcher.py and app.py live, and produce a single-file dist/launcher.exe on a clean machine.

Also: mark build_exe.sh executable by adding at the end of Copilot’s generation instructions:

After creating the file, remind the user to run: git update-index --add --chmod=+x build_exe.sh

⸻

Now output the complete contents of both files, in code blocks, exactly as they should appear on disk (tools/deps_scan.py first, then build_exe.sh). Do not include any extra commentary outside the code blocks.